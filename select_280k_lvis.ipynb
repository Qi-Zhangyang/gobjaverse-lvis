{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to download the union of gobjaverse and lvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the annotations files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# 'gobjaverse_280k_index_to_objaverse.json' is provided by the official.\n",
    "hf_hub_download(repo_id=\"alexzyqi/GPT4Point\", filename='gobjaverse_280k_index_to_objaverse.json', repo_type=\"dataset\", local_dir='annotations/280k_index_to_objaverse/')\n",
    "\n",
    "# objaverse-lvis annotations\n",
    "hf_hub_download(repo_id=\"alexzyqi/GPT4Point\", filename='ann_lvis.json', repo_type=\"dataset\", local_dir='annotations/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: get the gobjaverse to objaverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 'gobjaverse_280k_index_to_objaverse.json' is provided by the official.\n",
    "with open('annotations/280k_index_to_objaverse/gobjaverse_280k_index_to_objaverse.json', 'r') as index_file:\n",
    "    index_dict = json.load(index_file)\n",
    "\n",
    "swapped_dict = {v.split(\"/\")[-1].split(\".\")[0]: k for k, v in index_dict.items()}\n",
    "\n",
    "# 'reverse_280k_to_objaverse.json': \n",
    "with open('annotations/280k_index_to_objaverse/objaverse_280k_index_to_gobjaverse.json', 'w') as swapped_file:\n",
    "    json.dump(swapped_dict, swapped_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: select the 280k_lvis(dict format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations/ann_lvis.json', 'r') as ann_file, open('annotations/280k_index_to_objaverse/objaverse_280k_index_to_gobjaverse.json', 'r') as index_file:\n",
    "    ann_data = json.load(ann_file)\n",
    "    index_data = json.load(index_file)\n",
    "\n",
    "lvis_280k_dict = {}\n",
    "\n",
    "for category, id_list in ann_data.items():\n",
    "    for obj_id in id_list:\n",
    "        if obj_id in index_data:\n",
    "           lvis_280k_dict[obj_id] = index_data[obj_id]\n",
    "\n",
    "lvis_280k_list = list(lvis_280k_dict.values())\n",
    "\n",
    "with open('annotations/download_280k_lvis.json', 'w') as outfile:\n",
    "    json.dump(lvis_280k_list, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: split the 280k_lvis to 10 splits for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations/download_280k_lvis.json', 'r') as lvis_280k_file:\n",
    "    original_list = json.load(lvis_280k_file)\n",
    "\n",
    "chunk_size = len(original_list) // 10 \n",
    "\n",
    "result_chunks = [original_list[i:i+chunk_size] for i in range(0, len(original_list), chunk_size)]\n",
    "for i, chunk in enumerate(result_chunks):\n",
    "    filename = f\"annotations/split_280k_lvis/download_280k_lvis_{i+1}.json\"\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(chunk, json_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
